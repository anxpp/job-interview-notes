# Redis

## 数据类型

    *表示不常用类型

- string：字符串，最大512m
- list：集合
- set：无重复元素的列表
- zset：排序列表
- hash：哈希表
- *bitmap：位图，底层为string（v2.2）
- *stream：流（v5.0）
- *geo：位置，底层为zset（v3.2）
- *hyper：底层为string（v2.8.9）
- *bloomFilter：布隆过滤器，底层为string（v4.0）
- *module：（v6.0）

### string

    底层使用sds，有容量和长度的属性，相比c原生字符串可以O(1)得到长度

```c
struct sdshdr {
    unsigned int len;   // 记录buf数组中已使用字节的数量,等于SDS所保存字符串的长度
    unsigned int free;  // 记录buf数组中未使用字节的数量
    char buf[];         // char数组，用于保存字符串
};
```

### hash

    底层使用两个dictht实现, 与 go map 实现思想相似

```c
typedef struct dictht {
    dictEntry **table;          // 哈希表数组
    unsigned long size;         // 哈希表大小
    unsigned long sizemask;     // 哈希表大小掩码，用于计算索引值, 总是等于 size - 1
    unsigned long used;         // 该哈希表已有节点的数量
} dictht;
```

扩容时，dictht1 的键值对会 rehash 到 dictht2，完成后清理空间并交换两个 dictht 的角色。

rehash时渐进式的，每次查询（查找、添加、删除、修改）都会执行一次rehash，会维护 rehashidx 指针，从0开始。

过程：

```go
    dictht2[rehashidx], dictht1[rehashidx] = dictht1[rehashidx], null
    rehashidx++
```

渐进式hash可以避免一次性执行过多的 rehash 操作给服务器带来过大的负担，但是会使数据分布到两个 dictht 上，所以查找的时候需要到对应的 dictht 中执行。

### 跳表（zset）

    跳表是一种随机化的数据结构，底层是链表实现，每次添加节点都有可能向上层添加节点(上层对应值后下层同节点的指针)
    每次查找都从最上层找到对应区间，然后依次向下查找

比如有如下跳表

```shell

1 ->           5 ->                     10
1 ->      3 -> 5 ->      7 ->           10
1 -> 2 -> 3 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 
```

如果要查找 6 ，过程如下：

- 第3层二分找到 5~10
- 进一步第2层找到 5~7
- 第1层找到6，结束

与红黑树比较（官方解释有提到跳表实现更简单）

- 跳表底层基于链表，插入速度非常快
- 实现起来更简单
- 增加节点可以做到无锁，AVL树则因为可能会调整节点而必须加锁
- 获取中值，AVL平衡树更快
- 二者性能接近

### ziplist（hash、zset）

    大多数场景的键，其值都比较短，redis使用压缩表节约内存，时间换空间（数据量小，时间影响不大）

## 使用场景

- 计数器：string值为int时，支持使用自增自减
- 缓存：众所周知
- 查找表：kv内存数据库都可以
- 消息队列：list底层使用双向链表实现，可用作消息队列，不过推荐使用专业的消息队列
- 绘画缓存
- 好友关系：set可以求交集并集
- 排行榜：zset
- 分布式锁：setnx，需要给超时时间，防止解锁失败时产生死锁

## 数据淘汰策略

| 策略              | 说明                    |
|-----------------|-----------------------|
| volatile-lru    | 已设置过期时间的数据集，挑选最近最小的淘汰 |
| volatile-ttl    | 已设置过期时间的数据集，挑选将要过期的淘汰 |
| volatile-random | 已设置过期时间的数据集，随机选择淘汰    |
| volatile-lfu    | 已设置过期时间的数据集，访问频率最低的淘汰 |
| allkeys-lru     | 所有数据集中，挑选最近最小的淘汰      |
| allkeys-random  | 所有数据集中，随机选择淘汰         |
| allkeys-lfu     | 所有数据集中，访问频率最低的淘汰      |
| noeviction      | 禁止驱逐                  |

- lru：单链表+map，实现各个方法都以平均O(1)的开销执行
- lfu：双链表+两个map，实现各个方法都以平均O(1)的开销执行

*热点数据实现方式之一：预估热点数据最大的内存占用为M，redis内存最大使用量设置为M并设置淘汰策略为 allkeys-lru 即可

## 持久化

- RDB：快照，某个时间点的所有数据存放到硬盘
- AOF：将写命令追加到AOF文件末尾，策略可选always，everysec，no
    - always：每一条都写入磁盘，对性能影响较大
    - everysec：先写入缓冲，每秒刷入磁盘，推荐使用，性能影响很小，数据最多丢失1s
    - no：由操作系统决定何时刷入磁盘，不可控，按最坏情况考虑的话不合适使用

对比

| 对比项      | RDB | AOF |
|----------|-----|-----|
| 可读性      | 差   | 好   |
| 恢复速度     | 快   | 慢   |
| 文件体积     | 大   | 小   |
| 崩溃丢失数据范围 | 多   | 少   |

    因为aof会不断追加命令到aof文件，所以体积会变得越来越大，redis提供重写功能（简单的考虑自增操作，多次自增可以重写为一条set命令即可）

新版本支持两种方式同时启用，兼顾rdb和aof的优点：aof追加到rdb文件后面（rdb完成后替换掉aof文件，aof的时候，以rdb为前置数据追加写命令）

## 事务

    Redis 作者认为基本只会出现在开发环境的编程错误其实在生产环境基本是不可能出现的（例如对 String 类型的数据库键执行 LPUSH 操作），所以他觉得没必要为了这事务回滚机制而改变 Redis 追求简单高效的设计主旨。

redis的事务主要是将命令打包发送，提高性能。

语法错误型的事务可以保持原子性，运行时的错误（如对value为字符串的string自增）除了错误的命令不执行，其他命令会照常执行，不满足原子性。

如果需要保证原子性，可以使用lua脚本

## 复制

slaveof host port 添加从服务器，单向复制

过程：

- 主服务器创建快照文件，发送给从服务器，并在发送期间使用缓冲区记录执行的写命令。快照文件发送完毕之后，开始向从服务器发送存储在缓冲区中的写命令
- 从服务器丢弃所有旧数据，载入主服务器发来的快照文件，之后从服务器开始接受主服务器发来的写命令
- 主服务器每执行一次写命令，就向从服务器发送相同的写命令

可以配置主从链（a是b的主，b是c、d的主）

## 哨兵

哨兵监听整个集群，master下线后，自动选举新的master

保证高可用，哨兵也要集群部署

## 分片

- 客户端分片：不推荐，客户端通过一致性hash算法（或者按范围等）决定要访问的服务器
- 代理：选择服务器的决定权交给代理
- redis cluster：哈希环，哈希槽的数量为 1<<14 个？，使用虚拟节点缓解hash不均匀的情况