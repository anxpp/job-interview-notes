

商务智能（BI，Business Intelligence）是一种以提供决策分析性的运营数据为目的而建立的信息系统。是属于在线分析处理：On Line Analytical Processing(OLAP)，将预先计算完成的汇总数据，储存于魔方数据库(Cube) 之中，针对复杂的分析查询，提供快速的响应。在前10年，BI报表项目比较多，是数据仓库项目的前期预热项目（主要分析为主的阶段，是数据仓库的初级阶段），制作一些可视化报表展现给管理者。

它利用信息科技，将分散于企业内、外部各种数据加以整合并转换成知识，并依据某些特定的主题需求，进行决策分析和运算；
用户则通过报表、图表、多维度分析的方式，寻找解决业务问题所需要的方案；
这些结果将呈报给决策者，以支持策略性的决策和定义组织绩效，或者融入智能知识库自动向客户推送。



数据仓库基本定义

数据仓库(Data Warehouse)是一个面向主题的（Subject Oriented）、集成的（Integrated）、相对稳定的（Non-Volatile）、反映历史变化的（Time Variant）数据集合，用于支持管理决策和信息的全局共享。其主要功能是将组织透过资讯系统之联机事务处理(OLTP)经年累月所累积的大量资料，透过数据仓库理论所特有的资料储存架构，作一有系统的分析整理，以利各种分析方法如联机分析处理(OLAP)、数据挖掘(Data Mining)之进行，并进而支持如决策支持系统(DSS)、主管资讯系统(EIS)之创建，帮助决策者能快速有效的自大量资料中，分析出有价值的资讯，以利决策拟定及快速回应外在环境变动，帮助建构商业智能(BI)。[1]：引自全球数据仓库之父 W.H.Inmon。

所谓主题：是指用户使用数据仓库进行决策时所关心的重点方面，如：收入、客户、销售渠道等；所谓面向主题，是指数据仓库内的信息是按主题进行组织的，而不是像业务支撑系统那样是按照业务功能进行组织的。
所谓集成：是指数据仓库中的信息不是从各个业务系统中简单抽取出来的，而是经过一系列加工、整理和汇总的过程，因此数据仓库中的信息是关于整个企业的一致的全局信息。
所谓随时间变化：是指数据仓库内的信息并不只是反映企业当前的状态，而是记录了从过去某一时点到当前各个阶段的信息。通过这些信息，可以对企业的发展历程和未来趋势做出定量分析和预测。





数据湖（Data Lake）是一个存储企业的各种各样原始数据的大型仓库，其中的数据可供存取、处理、分析及传输。数据湖是以其自然格式存储的数据的系统或存储库，通常是对象blob或文件。数据湖通常是企业所有数据的单一存储，包括源系统数据的原始副本，以及用于报告、可视化、分析和机器学习等任务的转换数据。数据湖可以包括来自关系数据库（行和列）的结构化数据，半结构化数据（CSV，日志，XML，JSON），非结构化数据（电子邮件，文档，PDF）和二进制数据（图像，音频，视频）。





数据中台是指通过企业内外部多源异构的数据采集、治理、建模、分析，应用，使数据对内优化管理提高业务，对外可以数据合作价值释放，成为企业数据资产管理中枢。数据中台建立后，会形成数据API，为企业和客户提供高效各种数据服务




如何选择技术栈
Apache：运维麻烦，组件间兼容性需要自己调研。
CDH：国内使用最多的版本，但CM不开源，今年开始要收费。
HDP：开源，可以进行二次开发，但是没有CDH稳定，国内使用较少。

如何选择中间件

数据采集传输：Flume，Kafka，Sqoop ，Logstash，DataX
数据存储：MySql，HDFS，HBase，Redis，MongoDB
数据计算：Hive，Tez， Spark， Flink，Storm
数据可视化：Echarts、Superset、QuickBI、DataV
任务调度：Azkaban、Oozie
集群监控：Zabbix
元数据管理：Atlas



Flume和Sqoop


Ambari


一、综述
目前Hadoop发行版非常多，有华为发行版、Intel发行版、Cloudera发行版（CDH）等，所有这些发行版均是基于Apache Hadoop衍生出来的，之所以有这么多的版本，完全是由Apache Hadoop的开源协议决定的：任何人可以对其进行修改，并作为开源或商业产品发布/销售。(http://www.apache.org/licenses/LICENSE-2.0)。
CDH全称是Cloudera
国内绝大多数公司发行版是收费的，比如Intel发行版、华为发行版等，尽管这些发行版增加了很多开源版本没有的新feature，但绝大多数公司选择Hadoop版本时会将把是否收费作为重要指标，不收费的Hadoop版本主要有三个（均是国外厂商），分别是：

Cloudera版本（Cloudera’s Distribution Including Apache Hadoop，简称“CDH”）
Apache基金会hadoop
Hortonworks版本（Hortonworks Data Platform，简称“HDP”）
对于国内而言，绝大多数选择CDH版本。

二、社区版本与第三方发行版本的比较
1.Apache社区版本
优点：
完全开源免费。
社区活跃
文档、资料详实

缺点：
----复杂的版本管理。版本管理比较混乱的，各种版本层出不穷，让很多使用者不知所措。
----复杂的集群部署、安装、配置。通常按照集群需要编写大量的配置文件，分发到每一台节点上，容易出错，效率低下。
----复杂的集群运维。对集群的监控，运维，需要安装第三方的其他软件，如ganglia，nagois等，运维难度较大。
----复杂的生态环境。在Hadoop生态圈中，组件的选择、使用，比如Hive，Mahout，Sqoop，Flume，Spark，Oozie等等，需要大量考虑兼容性的问题，版本是否兼容，组件是否有冲突，编译是否能通过等。经常会浪费大量的时间去编译组件，解决版本冲突问题。

2.第三方发行版本（如CDH，HDP，MapR等）
优点：
----基于Apache协议，100%开源。
----版本管理清晰。比如Cloudera，CDH1，CDH2，CDH3，CDH4等，后面加上补丁版本，如CDH4.1.0 patch level 923.142，表示在原生态Apache Hadoop 0.20.2基础上添加了1065个patch。
----比Apache Hadoop在兼容性、安全性、稳定性上有增强。第三方发行版通常都经过了大量的测试验证，有众多部署实例，大量的运行到各种生产环境。
----版本更新快。通常情况，比如CDH每个季度会有一个update，每一年会有一个release。
----基于稳定版本Apache Hadoop，并应用了最新Bug修复或Feature的patch
----提供了部署、安装、配置工具，大大提高了集群部署的效率，可以在几个小时内部署好集群。
----运维简单。提供了管理、监控、诊断、配置修改的工具，管理配置方便，定位问题快速、准确，使运维工作简单，有效。

缺点：
----涉及到厂商锁定的问题。（可以通过技术解决）

三、第三方发行版本的比较
Cloudera：最成型的发行版本，拥有最多的部署案例。提供强大的部署、管理和监控工具。Cloudera开发并贡献了可实时处理大数据的Impala项目。
Hortonworks：不拥有任何私有（非开源）修改地使用了100%开源Apache Hadoop的唯一提供商。Hortonworks是第一家使用了Apache HCatalog的元数据服务特性的提供商。并且，它们的Stinger开创性地极大地优化了Hive项目。Hortonworks为入门提供了一个非常好的，易于使用的沙盒。Hortonworks开发了很多增强特性并提交至核心主干，这使得Apache Hadoop能够在包括Windows Server和Windows Azure在内的Microsft Windows平台上本地运行。

四、CDH，Apache Hadoop，HDP的比较
Apache Hadoop	CDH	HDP
管理工具	手工	Cloudera Manager	Ambari
收费情况	开源	社区版免费，企业版收费	免费




ETL，是英文 Extract-Transform-Load 的缩写，用来描述将数据从来源端经过抽取（extract）、转换（transform）、加载（load）至目的端的过程。

ELT是一个比较新潮的概念，相比于ETL，从功能上来说没有差异，只是换了一个顺序。差别在于，如果采用ELT的方案，首先把数据用一种高效的方式从数据源抽取出来，然后在数据仓库中进行数据的转换处理。这种ELT的方式相比于ETL有很大的优势，而本文介绍的偶数数据中台Lava中的数据同步工具，使用的就是ELT这种理念。

关于偶数数据中台里的数据同步工具产品设计作为一个数据同步工具，偶数的数据同步工具支持很多常用数据源比如DB2、Oracle、MySQL、SQLServer、Postgresql等关系型数据库以及HDFS等。

偶数的数据同步工具符合ELT的理念，把数据的转换处理交给目标数据仓库来做。并且很好的利用目标数据仓库，例如OushuDB的高效特性来进行数据同步，块级别的并发导入效率远远高于JDBC的方式导入







数据汇聚

数据中台不产生数据，数据其实来源于各个业务系统、数据库、网络环境等，是日常操作所产生的数据，多数存储在网络环境和存储平台中，且各个系统之间独立存在，很难直接使用，需要去进行数据抽取、采集、整合和处理，将异构数据采集到统一的平台进行存储，进而通过建模将数据进行加工处理，变为对业务有用的数据，只有这样才能有效汇聚数据，形成数据中台的统一数据资源。

数据存储计算

将采集补录、抽取整合的业务数据汇聚后，以数据形态存储，当下大数据发展的节奏让数据库技术也由传统关系型数仓架构，向Hadoop分布式架构演变，并随着业务实时性决策需要，推动融合MPP、SQL on Hadoop、流处理等大数据技术服务的实时流式计算存储应用，实现海量数据高效统一管理，为企业提供实时数据支撑。

数据治理

数据平台建好后，业务数据可能杂乱无章，数据质量低，需要经过一系列的治理提高数据质量，将数据统一起来进行管控，这个过程中就包括数据模型管理、数据标准管理、元数据管理、数据质量管理、生命周期管理、数据安全管理。

数据模型管理是根据业务对数据进行分层、整合处理，方便数据的分析应用；元数据管理方便技术人员进行分析数据来龙去脉以及对数据库底层数据质量进行把控；数据标准用来指定一系列标准，对元数据进行标准的检查；数据质量是根据一系列规则，对库表数据进行校验和整改；数据生命周期和安全贯穿整个流程，为数据保驾护航。

数据资产管理

经过数据汇聚、数据治理，已经形成的数据资源需要有统一的地方去进行管理，方便业务人员理解数据，这时就需要建立数据资产管理体系，需要先根据业务先形成资产目录，数据拥有者将自己的数据资产挂到对应的类目树，梳理成一套完整的资产目录，将数据资产开放出去，展示给业务人员或外部人员，提供企业的数据意识。

数据服务

经过前期一系列梳理工作，数据还没有真正发挥它的价值，而数据服务则是将数据资产转化成一种服务能力，那么如果我们需要调用某个数据资产要怎么操作使用？数据提供方又如何将数据资产提供给别人使用？这就是我们说的数据服务功能，帮助用户实现数据规划咨询，数据资产服务开放及数据可视化展示应用等。




数据中台架构设计原则
面向未来：应该能够很容易地将新出现的大数据、人工智能、机器学习应用和框架加入系统。新技术以前所未有的速度出现，如果数据中台不能快速适应变化，各部门可能很快就会自己另起炉灶，形成新的应用及数据孤岛。

需求驱动：数据中台的存在是为了更快、更好地满足业务部门的需求，因此其架构设计应该以如何快速处理需求为核心。

面向个体：系统的每个使用者面对的都是系统的一个方面，但是他们都应该能够从系统中获得他们需要的数据能力，自助完成他们的目标，达到最优的效率。

面向协作：考虑系统的每个使用者的行动如何影响整个系统的功能。个体用户对系统的使用会以自适应的方式影响整个系统的演进，例如，多个用户在有类似的数据能力需求时如何协同开发，我们的架构应该能清楚地掌握系统中核心元素之间的关系和连接。

面向变化：对于系统中所有的元素（用户、数据、应用、资源），架构设计必须考虑其变化和生命周期。

容错能力：对于数据中台这样复杂的系统，我们必须假设所有组件都有可能失败或出错。系统必须具备极强的容错性以及在发生大多数错误时自动恢复的能力。

数据安全：数据越来越成为一个公司的核心价值，数据中台是公司数据处理和能力共享的核心组件，我们要假设所有的规则都有人违背，一定会有人试图违规访问数据。数据中台应该能让每个用户都放心使用系统，而不用担心会使系统意外崩溃。

不要重复造轮子：应该尽量避免重复开发系统功能组件，系统中的数据和能力要能高效安全地在各个部门之间共享。这意味着每个用户在使用数据中台的时候，都能够对系统中的可用数据和能力有个全局视图。

兼顾灵活性和易用性：作为数据中台，如果把所有组件都做得傻瓜化，虽然对于新手来说很容易上手，但是在功能和效率上会有一定限制；如果提供很多灵活的选项，则新手可能就会淹没在复杂的系统配置中。必须在二者之间找到一个比较好的平衡。



计算存储平台：为数据中台提供计算和存储，存储可以存储结构化，半结构化，非结构化数据，计算有实时计算、离线计算，交互式计算，图计算等

数据集成开发平台：数据集成开发平台能最高效地使用底层的组件和数据，提供从源数据到数据能力的转换。数据集成平台是数据中台数据接入的入口。数据中台本身几乎不产生数据，所有数据来自于业务系统、日志、文件、网络等，这些数据分散在不同的网络环境和存储平台中，难以利用，很难产生业务价值。数据集成是数据中台必须提供的核心工具，把各种异构网络、异构数据源的数据方便地采集到数据中台中进行集中存储，为后续的加工建模做准备。数据集成方式一般有数据库同步、埋点、网络爬虫、消息队列等；从汇聚的时效性来分，有离线批量汇聚和实时采集，也有增量同步和全量同步。在数据集成的过程中一般会用到datax，flume，sqoop，canal等工具。

数据基础能力平台：常用的大数据平台组件、数据仓库、数据湖的工具、ETL工具、数据可视化工具等。通过数据集成模块汇聚到中台的数据没有经过处理，基本是按照数据的原始状态堆砌在一起的，这样业务还是很难使用。数据开发是一整套数据加工以及加工过程管控的工具，有经验的数据开发、算法建模人员利用数据加工模块提供的功能，可以快速把数据加工成对业务有价值的形式，提供给业务使用。数据开发模块主要面向开发人员、分析人员，提供离线、实时、算法开发工具，以及任务的管理、代码发布、运维、监控、告警等一系列集成工具，方便使用，提升效率

数据体系：有了数据集成、数据开发模块，中台已经具备传统数据仓库（后面简称：数仓）平台的基本能力，可以做数据的汇聚以及各种数据开发，就可以建立企业的数据体系。数据体系是中台的血肉，开发、管理、使用的都是数据。大数据时代，数据量大，增长快，业务对数据的依赖也会越来越高，必须考虑数据的一致性和可复用性，垂直的、烟囱式的数据和数据服务的建设方式注定不能长久存在。不同的企业因业务不同导致数据不同，数据建设的内容也不同，但是建设方法可以相似，数据要统一建设，建议数据按照贴源数据、统一数仓、标签数据、应用数据的标准统一建设，数据体系建设最终呈现的结果是一套完整、规范、标准、准确的数据体系，可以方便支撑数据应用。

数据资产管理：通过数据体系建立起来的数据资产较为偏技术，业务人员比较难理解。资产管理是以企业全员更好理解的方式，把企业的数据资产展现给企业全员（当然要考虑权限和安全管控），数据资产管理包括对数据资产目录、元数据、数据质量、数据血缘、数据生命周期等进行管理和展示，以一种更直观的方式展现企业的数据资产，提升企业的数据意识。

数据服务体系：前面利用数据集成、数据开发建设企业的数据资产，利用数据管理展现企业的数据资产，但是并没有发挥数据的价值。数据服务体系就是把数据变为一种服务能力，通过数据服务让数据参与到业务，激活整个数据中台，数据服务体系是数据中台存在的价值所在。企业的数据服务是千变万化的，中台产品可以带有一些标准服务，但是很难满足企业的服务诉求，大部分服务还是需要通过中台的能力快速定制。数据中台的服务模块并没有自带很多服务，而是提供快速的服务生成能力以及服务的管控、鉴权、计量等功能

运营体系和安全体系：通过前面的数据集成、数据开发、数据体系、数据资产管理、数据服务体系，已经完成了整个数据中台的搭建和建设，也已经在业务中发挥一定的价值。运营体系和安全管理是数据中台得以健康、持续运转的基础，如果没有它们，数据中台很可能像个一般项目一样，会在搭建起平台、建设部分数据、尝试一两个应用场景之后而止步，无法正常地持续运营，不能持续发挥数据的应用价值。这也就完全达不到建设数据中台的目标。数据安全管理是指对数据设定安全等级，按照相应国家/组织相关法案及监督要求，通过评估数据安全风险、制定数据安全管理制度规范、进行数据安全分级分类，完善数据安全管理相关技术规范，保证数据被合法合规、安全地采集、传输、存储和使用。企业通过数据安全管理，规划、开发和执行安全政策与措施，提供适当的身份以确认、授权、访问与审计等功能。数据的安全治理应贯穿于数据的整个生命周期。


https://wiki.mbalib.com/wiki/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0

核心思想是数据共享





（1）数据采集

① Sqoop。Sqoop是一种用于Hadoop和结构化数据存储（如关系型数据库和大型主机）之间高效传输批量数据的工具。Sqoop可将数据从外部结构化数据库存储导入Hadoop分布式文件系统，或其他分布式存储系统，如Hive和HBase；它也可以用于从Hadoop中提取数据，并将其导入到外部结构化数据存储。Sqoop的功能有两个，一是将数据从关系型数据库或大型主机导入到Hadoop平台，导入进程中的输入内容是数据库表或主机数据集；二是将数据从Hadoop平台导出到关系型数据库或大型主机，Sqoop的导出过程会并行地从HDFS中读取所需数据，并将它们解析为记录。如果导出到数据库，则将它们作为新的行插入到目标数据库表中。如果导出到大型主机，则直接形成数据集，供外部应用程序或用户使用。

② Flume。Flume是一种分布式的、高可靠的、高可用的，用于高效收集、聚合和移动大量日志数据的系统。Flame使用基于数据流的简单灵活的架构。Flume支持在日志系统中定制各类数据发送方，用于收集数据，同时也提供对数据进行简单处理并写到各种数据接收方的能力。Flume的功能包括：从固定目录下采集日志信息到目的地（如HDFS、HBase、Kafka）、实施采集日志信息到目的地、支持级联（多个Agent对接起来）、支持按照用户定制实现数据采集。

③ Kafka。Kafka是一种高吞吐量的分布式发布——订阅消息系统。Kafka主要用于处理活跃的流式数据，具有发布、订阅信息流、以容错方式存储信息流和处理信息流这三个关键的功能。通常来说Flume采集数据的速度和下游处理的速度是不同步的，因此实时架构平台都会用一个消息中间件来缓冲，而Kafka是常见的热门选择。

（2）数据处理

① MapReduce。MapReduce是一种大数据计算模型，它将运行于大规模集群上的复杂并行计算的过程高度抽象为两个函数 —— Map和Reduce，通过这两个函数实现大数据计算过程。MapReduce的优势在于，其易于编程（简单地实现一些接口就可以完成一个分布式程序），具有良好的扩展能力（当计算资源不能够得到满足的时候可以通过简单地增加机器来扩展它的计算能力），且容错性也比较高（一台服务器宕机了，可以把上面的计算任务移动到另一个节点上运行）。MapReduce的局限在于，实时计算效果较差，不适合处理流计算，数据作业会写入磁盘造成大量的I/O开销。

② Hive。Hive是基于Hadoop的数据仓库软件，可以用来进行数据提取转化加载（ETL），在Hadoop中存储、查询和分析大规模数据。Hive定义了类SQL查询语言HiveQL，提供了类SQL的查询功能。Hive查询的基本原理是将HiveQL语句自动转换为MapReduce任务，支持MapReduce、Tez、Spark等计算引擎。Hive的特性包括：使用HiveQL可以通过类SQL查询的方式轻松访问数据；包含多种文件格式的元数据服务；可以直接访问HDFS文件或其他数据存储系统（如HBase）中的文件；支持MapReduce、Tez、Spark等多种计算引擎，可以根据不同的数据处理场景选择合适的计算引擎。


③ Spark。Spark是使用内存计算的开源大数据并行计算框架，可以应对复杂的大数据处理场景。Spark是一个用于快速处理大规模数据的通用引擎，其内核是由Scala语言开发的，同时也提供了Java、Python和R语言等开发编程接口。Spark中有几个重要的概念，包括RDD（一个只读的、可分区的弹性分布式数据集。这个数据集的全部或部分内容可以缓存在内存中，在多次计算之间重用。Spark所有组件的计算操作都是针对RDD的操作）、DAG（是有向无环图的英文缩写，反映RDD之间的依赖关系）、Executor（是运行在工作节点Worker Node上的一个进程，负责运行任务，并为应用程序存储数据）。Spark的基本工作流程如下图所示：

④ Storm。Storm是Twitter开源的分布式实时大数据处理框架，被业界称为实时版Hadoop。随着越来越多的场景对Hadoop的MapReduce高延迟无法容忍，比如网站统计、推荐系统、预警系统、金融系统(高频交易、股票)等等，大数据实时处理解决方案（流计算）的应用日趋广泛，目前已是分布式技术领域最新爆发点，而Storm更是流计算技术中的佼佼者和主流。

⑤ Flink。Flink是由Apache软件基金会开发的开源流处理框架，其核心是用Java和Scala编写的分布式流数据流引擎。Flink以数据并行和流水线方式执行任意流数据程序，Flink的流水线运行时系统可以执行批处理和流处理程序。此外，Flink的运行时本身也支持迭代算法的执行。Flink程序在执行后被映射到流数据流，每个Flink数据流以一个或多个源（数据输入，例如消息队列或文件系统）开始，并以一个或多个接收器（数据输出，如消息队列、文件系统或数据库等）结束。Flink可以对流执行任意数量的变换，这些流可以被编排为有向无环数据流图，允许应用程序分支和合并数据流。Flink可能是下一代的常用数据中台，因为其可以将离线计算和实时计算比较好地合并。
⑥ Beam。Beam（原名Google DataFlow）是Google在2016年2月份贡献给Apache基金会的Apache孵化项目，被认为是继MapReduce，GFS和BigQuery等之后，Google在大数据处理领域对开源社区的又一个非常大的贡献。Apache Beam的主要目标是统一批处理和流处理的编程范式，为无限，乱序，web-scale的数据集处理提供简单灵活，功能丰富以及表达能力十分强大的SDK。Apache Beam项目重点在于数据处理的编程范式和接口定义，并不涉及具体执行引擎的实现，Apache Beam希望基于Beam开发的数据处理程序可以执行在任意的分布式计算引擎上。

（3）数据存储

① HDFS。HDFS是使用Java实现的、分布式的、可横向扩展的分布式文件系统。分布式文件系统是一种将文件分布存储在网络中多个计算机节点上的文件系统。分布式文件系统需要涉及网络中多台计算机，比本地文件系统更复杂。HDFS可以存储超大文件，采用流式数据访问模式，运行于通用X86服务器上。HDFS可以容忍硬件出错，在某个节点发生故障的时候，可以及时由其他正常节点继续向用户提供服务。HDFS在数据处理时，具有很高的数据吞吐率，对于大数据应用来说，HDFS是一个非常好的分布式数据存储系统。HDFS可以存储超大文件，其采用流式数据访问模式，其业务操作对象是文件，包括读写删等。

② HBase。HBase是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统。HBase是非关系型数据库，它适用于结构化和非结构化数据的存储。HBase的数据是基于列而不是基于行的模式，利用HBase技术可以在廉价服务器上搭建起大规模结构化存储集群。HBase利用Hadoop HDFS作为其文件存储系统，以Hadoop MapReduce（Hadoop的分布式计算框架）来处理海量数据，并且将ZooKeeper（Hadoop的协调服务）作为协同服务。
③ Redis。是一个开源的使用ANSIC语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。Redis是一个高性能的key-value数据库。 redis的出现，很大程度补偿了memcached这类key/value存储的不足，在部分场合可以对关系数据库起到很好的补充作用。
④ MongoDB。ongoDB是一个基于分布式文件存储的数据库。由C++语言编写。旨在为WEB应用提供可扩展的高性能数据存储解决方案。MongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。它支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。MongoDB最大的特点是它支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。

（4）资源管理和调度

① YARN。YARN是一个通用的资源管理模块，可以为上层应用提供统一的资源管理和调度。YARN可以统一管理多种计算框架，具有资源利用高、运维成本低等优点。YARN实现了“一个集群多个框架”，可以统一调度集群内的计算资源，大大提高了资源的利用率。而管理员仅需要运维一个集群，大大降低了运维成本。YARN可以在同个集群内部署不同的计算框架，实现不同计算框架之间的数据共享。

② Zookeeper。ZooKeeper是一个分布式协调服务，可以为分布式应用程序提供配置维护、域名服务、分布式同步等服务，从而减轻分布式应用程序所承担的协调任务。ZooKeeper的目标是基于自身去构建更为复杂的分布式应用场景，例如分布式数据库、分布式消息系统和分布式搜索引擎等实时性要求很高的系统，所以它自身被设计的非常快速、非常简单。ZooKeeper将Znode（是一种节点的空间结构）的数据保存在内存中，这是它能实现高吞吐量和低延迟性能的重要原因。为了增强可靠性，ZooKeeper会同时将这些数据以操作日志和快照的形式持久化到磁盘上，以免进程重启的时候数据丢失。

③ Mesos。Mesos是一个集群管理器类似于YARN，提供了有效的、跨分布式应用或框架的资源隔离和共享，可以运行 Hadoop、MPI、Hypertable、Spark。Mesos的主要目标就是去帮助管理不同框架（或者应用栈）间的集群资源。例如，有一个业务需要在同一个物理集群上同时运行Hadoop，Storm及 Spark。这种情况下，现有的调度器是无法完成跨框架间的如此细粒度的资源共享的。Hadoop 的 YARN 调度器是一个中央调度器，它可以允许多个框架运行在一个集群里。但是，要使用框架特定的算法或者调度策略的话就变得很难了，因为多个框架间只有一种调度算法。





数据抽取层： sqoop 和 flume 是两大主流工具，其中 sqoop 作为结构化数据（关系型数据库）离线抽取，flume 作为非结构化日志接入；
数据存储层： Hadoop 文件系统 Hdfs 大家都比较了解，而 kafka 作为流式数据总线应用也非常广泛；
计算与调度层 ，包括：离线计算：离线计算主要是 hive，spark，也有部分选用 tez实时计算：前些年 storm，spark 比较流行，最近几年大家纷纷往 Flink 转型数据调度：除了像 Airflow Azkaban Oozie 等，易观开源的 Dolphin-scheduler 也非常活跃
数据引擎层： 也就是我们常说的 OLAP 层，我们看到这一层里的选择非常多，就不一一列举了，（业务需求带动技术进步的典型，选择丰富主要是可以适配不同的数据应用场景）。从概念上讲分为 ROLAP、MOLAP 以及两者混搭。MOLAP 提前做一些预计算，以生成 Cube 的方式，达到空间换取查询效率；而 ROLAP 是即查即用，效率完全取决于查询引擎的性能，我个人认为从将来看，ROLAP 的趋势会更加明显，因为没有中间的数据链路。但目前看来，没有一个统一的引擎足以支撑各类数据场景（这或许是将来的机会~）；
数据可视化层： 比较主流的有 Metabase、Superset、Redash，也可以选择阿里、百度的一些开源控件。



1. 与数据仓库的对比

数据仓库是一个面向主题的、集成的、相对稳定的、反映历史变化的数据集合，用于支持管理决策。因此，其重点在于数据的集合。数据仓库可使用维度建模方法论从业务过程中抽象出通用维度与度量，组成数据模型，为决策分析提供通用的数据分析能力。

2. 与数据湖的对比

与数据中台相关的概念还有数据湖（Data Lake）。数据湖是一种数据存储理念，作为一个集中的存储库，它可以以自然格式存储任意规模的数据，包括来自关系数据库行和列的结构化数据，XML、JSON、日志等半结构化数据，电子邮件、文档等非结构化数据，以及图像、音视频等的二进制数据，从而实现数据的集中式管理。

目前Hadoop是最常见的实现数据湖概念的技术。比如HBase可让数据湖保存海量数据，Spark可以使得数据湖批量分析数据，而Flink等可让数据湖实时接入和处理IoT数据等。

3. 与BI的对比

BI（商业智能）是分析数据并获取洞察，进而帮助企业做出决策的一系列方法、技术和软件。相比数据仓库，BI还包含数据挖掘、数据可视化等工具，并可支持用户在一定范围内任意组合维度与指标，从而上升到支持决策的层面，而不只是作为数据仓储。

4. 与大数据的对比

数据中台也不等于大数据。数据中台是基于大数据、人工智能等技术构建的数据采、存、通、管、用的平台。

数据中台需要以Hadoop、Spark等为代表的大数据处理技术做支撑，但绝不能将数据中台与大数据划等号。数据中台不只有大数据处理技术，还包括智能算法、与业务联动的特性、数据资产、数据工具等。

5. 小结

可以说数据中台是上述概念和技术的集大成者。

首先，大数据丰富的数据计算和存储技术为数据中台提供了强大的数据处理能力。
其次，数据中台作为企业数据的集结地，其底层也当然承载着数据湖的职能。
再次，数据仓库对数据的分域建模是数据中台的重要部分，它承载着将企业数据治理得井井有条的职能。
最后，基于强大的数据能力，结合业务场景提供实时、智能的服务和应用是数据中台的核心价值体现。








gcd（greatest common divisor）为最大公约数，lcm（least common multiple）为最小公倍数。

gcd算法
下面是欧几里得算法（Euclidean algorithm），也叫辗转相除法。

int gcd(int a, int b) {
if (b == 0) {
return a;
}

    return gcd(b, a % b);
}
1
2
3
4
5
6
7
二进制gcd算法
与计算余数的执行速度相比，计算机执行减法运算、奇偶性判断和折半运算（通过位运算）的速度更快。下面的二进制gcd算法避免了欧几里得算法中对余数的计算过程：

#include <algorithm>

int gcd(int a, int b) {
// make sure a >= b.
if (a < b) {
std::swap(a, b);
}

    if (b == 0) {
        return a;
    }

    bool a_isodd = a & 1;
    bool b_isodd = b & 1;

    if (a_isodd && b_isodd) {
        return gcd((a - b) >> 1, b);
    } else if (a_isodd && !b_isodd) {
        return gcd(a, b >> 1);
    } else if (!a_isodd && b_isodd) {
        return gcd(a >> 1, b);
    }

    // both a and b are even numbers.
    return gcd(a >> 1, b >> 1) << 1;
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
其中a ≥ b a \ge ba≥b，那么：

如果a aa和b bb都是奇数，则g c d ( a , b ) = g c d ( a − b 2 , b ) gcd(a, b) = gcd(\frac {a - b} {2}, b)gcd(a,b)=gcd(
2
a−b
​
,b)
如果a aa是奇数，b bb都是偶数，则g c d ( a , b ) = g c d ( a , b 2 ) gcd(a, b) = gcd(a, \frac {b} {2})gcd(a,b)=gcd(a,
2
b
​
)
如果a aa是偶数，b bb都是奇数，则g c d ( a , b ) = g c d ( a 2 , b ) gcd(a, b) = gcd(\frac {a} {2}, b)gcd(a,b)=gcd(
2
a
​
,b)
如果a aa和b bb都是偶数，则g c d ( a , b ) = 2 ⋅ g c d ( a 2 , b 2 ) gcd(a, b) = 2 \cdot gcd(\frac {a} {2}, \frac {b} {2})gcd(a,b)=2⋅gcd(
2
a
​
,
2
b
​
)
lcm算法
两个整数的最小公倍数与最大公因数之间有如下的关系：

l c m ( a , b ) = ∣ a ⋅ b ∣ g c d ( a , b ) lcm(a, b) = \frac {\lvert a \cdot b \rvert} {gcd(a, b)}lcm(a,b)=
gcd(a,b)
∣a⋅b∣
​


int lcm(int a, int b) {
return a * b / gcd(a, b);
}
1
2
3
参考
《算法导论》
————————————————
版权声明：本文为CSDN博主「海将河推走」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/weixin_43669941/article/details/109629555
